% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/drQuality.R
\name{drQuality}
\alias{drQuality}
\title{Unsupervised dimensionality reduction quality assessment}
\usage{
drQuality(
  object,
  dimred = reducedDimNames(object),
  Kup = ceiling(ncol(object)/2),
  BPPARAM = BiocParallel::bpparam()
)
}
\arguments{
\item{object}{A \code{SingleCellExperiment} object.}

\item{dimred}{\code{character()} with the \code{reducedDims} low dimension
embeddings to be assessed. Default is to use all available
with \code{reducedDimNames(object)}.}

\item{Kup}{\code{numeric(1)} defining the maximum number of nearest
neighbours to compute the quality metrics \code{Rx} for. Default is
\code{ceiling(ncol(object)/2)}, i.e. neighborhood sizes of 1 up to
half the number of cells. Setting \code{Kup} to NA will compute the
\code{Rx} metric for all values (i.e. 1 to N-2). This will however
be at a considerable cost in computation time.}

\item{BPPARAM}{An optional instance of class \code{BiocParallelParam}
defining the parallelisation backend to be used during
evaluation. See \code{?BiocParallel::BiocParallelParam} and the
\code{BiocParallel} package documentation for details. The default
value is the one returned by \code{\link[BiocParallel:register]{BiocParallel::bpparam()}}.}
}
\value{
A list containing a vector of \code{Rx} values and a \code{AUC}
scalar.
}
\description{
Rank-based criteria measuring the high-dimensional neighborhood
preservation in the low-dimensional embedding from Lee et
al. (2009, 2010). These criteria are used in the experiments
reported in de Bodt et al. (2020).
}
\details{
The \code{drQuality()} function computes the dimensionality reduction
quality assessment criteria \eqn{R_{NX}(K)} (\code{Rx}) and area under
the curve (\code{AUC}), as defined in Lee et al. (2009, 2010, 2103) and
Lee and Verleysen (2009, 2010) and as used in the experiments
reported in de Bodt et al. (2020).

These criteria measure the neighborhood preservation around the
data points from the high-dimensional space to the
low-dimensional space.

Based on the high-dimensional and low-dimensional Euclidean
distances, the sets \eqn{v_i^K} (resp. \eqn{n_i^K}) of the K
nearest neighbours of data point i in the high-dimensional space
(resp. low-dimensional space) can first be computed.

Their average normalized agreement develops as

\deqn{Q_{NX}(K) = \frac{1}{N} \times \sum_{i=1}^{N} \frac{|v_i^K \cap n_i^K|}{K}}{%%
      Q_{NX}(K) = (1/N) * Sum_{i=1}^{N} |intersect(v_i^K, n_i^K)|/K}

where N refers to the number of data points and
\eqn{\cap}{intersect()} to the set intersection
operator. \eqn{Q_{NX}(K)} ranges between 0 and 1; the closer to 1,
the better.

As the expectation of \eqn{Q_{NX}(K)} with random low-dimensional
coordinates is equal to \eqn{\frac{K}{N-1}}{K/(N-1}, which is
increasing with K

\deqn{R_{NX}(K) = \frac{(N-1) \times Q_{NX}(K)-K}{N-1-K}}{%%
      R_{NX}(K) = ((N-1)*Q_{NX}(K)-K)/(N-1-K)}

enables to more easily compare different neighbourhood sizes
K. \eqn{R_{NX}(K)} ranges between -1 and 1, but a negative value
indicates that the embedding performs worse than
random. Therefore, \eqn{R_{NX}(K)} typically lies between 0 and 1.
The \eqn{R_{NX}(K)} values of K ranging from 1 to N-2 can be
displayed as a curve with a log scale for K, as closer neighbours
typically prevail.

The area under the resulting curve (AUC) is a scalar score that
grows with dimensionality reduction quality, quantified at all
scales with an emphasis on small ones. The AUC lies between -1 and
1, but a negative value implies performances which are worse than
random.

Given a dataset with N cells, the function has \eqn{O(N^2 \times log(N))}
time complexity. The \code{Kup} parameter sets the maximum neighborhood
size when computing the quality criteria, that is computed only
for the neighborhood sizes of K equal to 1 up to Kup, as opposed
to all possible neighborhood sizes (for \code{Kup} set to \code{NA}). This
reduces the time complexity to
\eqn{O(N \times Kup \times log(N))}{O(N * Kup * log(N))}.
Setting \code{Kup} can hence be run using much larger dataset, provided
that \code{Kup} is small compared to the total number of cells N.
}
\references{
\itemize{
\item Lee, J. A., & Verleysen, M. (2009). Quality assessment of
dimensionality reduction: Rank-based criteria. Neurocomputing,
72(7-9), 1431-1443.
\item Lee, J. A., & Verleysen, M. (2010). Scale-independent quality
criteria for dimensionality reduction. Pattern Recognition
Letters, 31(14), 2248-2257.
\item C. de Bodt, D. Mulders, M. Verleysen and J. A. Lee,
"Fast Multiscale Neighbor Embedding," in IEEE Transactions on
Neural Networks and Learning Systems, 2020, doi:
10.1109/TNNLS.2020.3042807.
\item Lee, J. A., & Verleysen, M. (2009). Quality assessment of
dimensionality reduction: Rank-based criteria. Neurocomputing,
72(7-9), 1431-1443.
\item Lee, J. A., & Verleysen, M. (2010). Scale-independent quality
criteria for dimensionality reduction. Pattern Recognition
Letters, 31(14), 2248-2257.
\item Lee, J. A., Renard, E., Bernard, G., Dupont, P., & Verleysen,
M. (2013). Type 1 and 2 mixtures of Kullbackâ€“Leibler divergences
as cost functions in dimensionality reduction based on
similarity preservation. Neurocomputing, 112, 92-108.
}
}
\seealso{
\code{\link[=runFMSSNE]{runFMSSNE()}}, \code{\link[=runFMSSNE]{runFMSSNE()}}, \code{\link[=runMSTSNE]{runMSTSNE()}} and \code{\link[=runMSSNE]{runMSSNE()}} for
the functions that perform the multi-scale stochastic neighbour
embeddings.
}
\author{
Laurent Gatto
}
